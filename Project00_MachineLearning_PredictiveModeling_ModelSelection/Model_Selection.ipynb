{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection for predictive modeling tool (Early screening for oral cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains the steps followed to select the optimal model for classifying oral cancer lesions based on colour images. A mass-screening tool was developed (in MATLAB/Python) based on this work. For more details, visit IIT Roorkee Masters thesis repository **(Belvin Thomas , \"Identification and classification of oral cancer lesions in color images using SVM and ANN\", 2013)**\n",
    "\n",
    "The model selection with optimal parameters is an important step in the development of a predictive modelling tool which can efficiently handle the bias-variance trade-off. It ensures that the final model is capable of effectively handling the issues of underfitting and overfitting. **An ensemble of the selected models and associated parameters is suggested for optimum generalisation.** This will ensure unbiased prediction while dealing with in an unseen image in a real-world mass-screening scenario.\n",
    "\n",
    "## This file contains :\n",
    "\n",
    "**1) Loading the cleaned data:** It contains texture features obtained from a repository of cancerous and non-cancerous images. Suitable features are selected from a set of texture features based on Gray level co-occurrance and Grey level run length. \n",
    "\n",
    "        For more details about the data and feature selection mechanism, visit the thesis cited above.\n",
    "\n",
    "**2) Splitting of data:** Data os split into training-validation-test dataset at 60-20-20 ratio.\n",
    "\n",
    "**3)Fitting a base model, cross validation and hyperparameter tuning based on following machine learning algorthms:**\n",
    "\n",
    "         - Logistic Regression\n",
    "         - Support Vector Machines (SVM)\n",
    "         - Multi-Layer Perceptron (MLP)\n",
    "         - Random forest classifier\n",
    "         - Gradient Boosting classifier\n",
    "         \n",
    "Machine learning algorithm implementations from *scikit-learn library* is used to train the models. Hyperparameters are tuned using GridsearchCV\n",
    "\n",
    "For the full dataset and more test data contact me belvinthomas@gmail.com\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.315018</td>\n",
       "      <td>0.105060</td>\n",
       "      <td>0.075914</td>\n",
       "      <td>0.064558</td>\n",
       "      <td>0.767077</td>\n",
       "      <td>0.770861</td>\n",
       "      <td>0.769463</td>\n",
       "      <td>0.088371</td>\n",
       "      <td>0.087806</td>\n",
       "      <td>0.089052</td>\n",
       "      <td>0.088658</td>\n",
       "      <td>0.566530</td>\n",
       "      <td>0.059893</td>\n",
       "      <td>0.277701</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.393685</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>0.065507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.597311</td>\n",
       "      <td>0.456494</td>\n",
       "      <td>0.403967</td>\n",
       "      <td>0.367882</td>\n",
       "      <td>0.399237</td>\n",
       "      <td>0.373282</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>0.336841</td>\n",
       "      <td>0.312095</td>\n",
       "      <td>0.290886</td>\n",
       "      <td>0.264992</td>\n",
       "      <td>0.511623</td>\n",
       "      <td>0.128474</td>\n",
       "      <td>0.175892</td>\n",
       "      <td>0.339991</td>\n",
       "      <td>0.433176</td>\n",
       "      <td>0.064335</td>\n",
       "      <td>0.052067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.489999</td>\n",
       "      <td>0.256581</td>\n",
       "      <td>0.220746</td>\n",
       "      <td>0.210259</td>\n",
       "      <td>0.487443</td>\n",
       "      <td>0.454825</td>\n",
       "      <td>0.444068</td>\n",
       "      <td>0.258086</td>\n",
       "      <td>0.259474</td>\n",
       "      <td>0.264092</td>\n",
       "      <td>0.258970</td>\n",
       "      <td>0.419175</td>\n",
       "      <td>0.097771</td>\n",
       "      <td>0.161377</td>\n",
       "      <td>0.362233</td>\n",
       "      <td>0.275433</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.049042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666515</td>\n",
       "      <td>0.744350</td>\n",
       "      <td>0.584654</td>\n",
       "      <td>0.490782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044284</td>\n",
       "      <td>0.106833</td>\n",
       "      <td>0.423656</td>\n",
       "      <td>0.400398</td>\n",
       "      <td>0.388102</td>\n",
       "      <td>0.368839</td>\n",
       "      <td>0.685056</td>\n",
       "      <td>0.030992</td>\n",
       "      <td>0.411515</td>\n",
       "      <td>0.632773</td>\n",
       "      <td>0.476661</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>0.022316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.483350</td>\n",
       "      <td>0.463071</td>\n",
       "      <td>0.261286</td>\n",
       "      <td>0.253401</td>\n",
       "      <td>0.273840</td>\n",
       "      <td>0.465242</td>\n",
       "      <td>0.443937</td>\n",
       "      <td>0.423321</td>\n",
       "      <td>0.395139</td>\n",
       "      <td>0.605882</td>\n",
       "      <td>0.058807</td>\n",
       "      <td>0.289854</td>\n",
       "      <td>0.499319</td>\n",
       "      <td>0.353755</td>\n",
       "      <td>0.014066</td>\n",
       "      <td>0.081336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels        F1        F2        F3        F4        F5        F6  \\\n",
       "0       1  0.315018  0.105060  0.075914  0.064558  0.767077  0.770861   \n",
       "1       1  0.597311  0.456494  0.403967  0.367882  0.399237  0.373282   \n",
       "2       1  0.489999  0.256581  0.220746  0.210259  0.487443  0.454825   \n",
       "3       1  0.666515  0.744350  0.584654  0.490782  0.000000  0.044284   \n",
       "4       1  0.686092  0.527778  0.483350  0.463071  0.261286  0.253401   \n",
       "\n",
       "         F7        F8        F9       F10       F11       F12       F13  \\\n",
       "0  0.769463  0.088371  0.087806  0.089052  0.088658  0.566530  0.059893   \n",
       "1  0.365941  0.336841  0.312095  0.290886  0.264992  0.511623  0.128474   \n",
       "2  0.444068  0.258086  0.259474  0.264092  0.258970  0.419175  0.097771   \n",
       "3  0.106833  0.423656  0.400398  0.388102  0.368839  0.685056  0.030992   \n",
       "4  0.273840  0.465242  0.443937  0.423321  0.395139  0.605882  0.058807   \n",
       "\n",
       "        F14       F15       F16       F17       F18  \n",
       "0  0.277701  0.500227  0.393685  0.016851  0.065507  \n",
       "1  0.175892  0.339991  0.433176  0.064335  0.052067  \n",
       "2  0.161377  0.362233  0.275433  0.043811  0.049042  \n",
       "3  0.411515  0.632773  0.476661  0.013883  0.022316  \n",
       "4  0.289854  0.499319  0.353755  0.014066  0.081336  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "oc = pd.read_csv('OC_data_cleaned.csv')\n",
    "oc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-Validation-Test Data split (0.6-0.2-0.2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = oc.drop('Labels', axis=1)\n",
    "labels = oc['Labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "for dataset in [y_train, y_val, y_test]:\n",
    "    print(round(len(dataset) / len(labels), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('OCtrain_features.csv', index=False)\n",
    "X_val.to_csv('OCval_features.csv', index=False)\n",
    "X_test.to_csv('OCtest_features.csv', index=False)\n",
    "\n",
    "y_train.to_csv('OCtrain_labels.csv', index=False)\n",
    "y_val.to_csv('OCval_labels.csv', index=False)\n",
    "y_test.to_csv('OCtest_labels.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression - Cross validation and hyperparameter (C) tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "tr_features = pd.read_csv('OCtrain_features.csv')\n",
    "tr_labels = pd.read_csv('OCtrain_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 152}\n",
      "\n",
      "0.524 (+/-0.021) for {'C': 0.001}\n",
      "0.906 (+/-0.052) for {'C': 0.01}\n",
      "0.931 (+/-0.037) for {'C': 0.1}\n",
      "0.938 (+/-0.035) for {'C': 1}\n",
      "0.955 (+/-0.042) for {'C': 10}\n",
      "0.958 (+/-0.035) for {'C': 100}\n",
      "0.958 (+/-0.052) for {'C': 152}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100,152]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(lr, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=152, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OCmodel_LR.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, 'OCmodel_LR.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM - Model fitting, Cross validation and hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "0.944 (+/-0.06) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.937 (+/-0.064) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.944 (+/-0.046) for {'C': 0.1, 'kernel': 'poly'}\n",
      "0.528 (+/-0.026) for {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "0.955 (+/-0.028) for {'C': 1, 'kernel': 'linear'}\n",
      "0.941 (+/-0.047) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.962 (+/-0.04) for {'C': 1, 'kernel': 'poly'}\n",
      "0.253 (+/-0.118) for {'C': 1, 'kernel': 'sigmoid'}\n",
      "0.972 (+/-0.047) for {'C': 10, 'kernel': 'linear'}\n",
      "0.958 (+/-0.06) for {'C': 10, 'kernel': 'rbf'}\n",
      "0.965 (+/-0.062) for {'C': 10, 'kernel': 'poly'}\n",
      "0.233 (+/-0.108) for {'C': 10, 'kernel': 'sigmoid'}\n",
      "0.965 (+/-0.049) for {'C': 100, 'kernel': 'linear'}\n",
      "0.948 (+/-0.073) for {'C': 100, 'kernel': 'rbf'}\n",
      "0.952 (+/-0.07) for {'C': 100, 'kernel': 'poly'}\n",
      "0.226 (+/-0.104) for {'C': 100, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf','poly','sigmoid'],\n",
    "    'C': [0.1, 1, 10,100]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(svc, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OCmodel_SVM.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, 'OCmodel_SVM.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP - Model fitting, Cross validation and hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "\n",
      "0.931 (+/-0.081) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.675 (+/-0.503) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.628 (+/-0.271) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.941 (+/-0.064) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.48 (+/-0.313) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.509 (+/-0.641) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.952 (+/-0.05) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.608 (+/-0.294) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.781 (+/-0.368) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.948 (+/-0.072) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.754 (+/-0.238) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.9 (+/-0.079) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.945 (+/-0.083) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.539 (+/-0.404) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.906 (+/-0.052) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.941 (+/-0.077) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.881 (+/-0.153) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.902 (+/-0.137) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.945 (+/-0.083) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.732 (+/-0.39) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.865 (+/-0.059) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.945 (+/-0.07) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.576 (+/-0.195) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.847 (+/-0.087) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.938 (+/-0.074) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.657 (+/-0.251) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.713 (+/-0.353) for {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.938 (+/-0.091) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.717 (+/-0.579) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.57 (+/-0.229) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.944 (+/-0.063) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.532 (+/-0.404) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.699 (+/-0.345) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.948 (+/-0.072) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.656 (+/-0.345) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.61 (+/-0.458) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.938 (+/-0.064) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.92 (+/-0.09) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.899 (+/-0.095) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.934 (+/-0.085) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.482 (+/-0.425) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.865 (+/-0.072) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.948 (+/-0.062) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.855 (+/-0.151) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.892 (+/-0.061) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.948 (+/-0.057) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.903 (+/-0.09) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.875 (+/-0.07) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.948 (+/-0.072) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.488 (+/-0.592) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.819 (+/-0.104) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.931 (+/-0.097) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.826 (+/-0.088) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.861 (+/-0.145) for {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.938 (+/-0.041) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.566 (+/-0.317) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.558 (+/-0.288) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.945 (+/-0.067) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.504 (+/-0.036) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.545 (+/-0.252) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.941 (+/-0.064) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.485 (+/-0.447) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.493 (+/-0.034) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (3,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.945 (+/-0.07) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.647 (+/-0.343) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.896 (+/-0.067) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.948 (+/-0.058) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.49 (+/-0.037) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.892 (+/-0.077) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.948 (+/-0.072) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.691 (+/-0.419) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.837 (+/-0.371) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.945 (+/-0.067) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.562 (+/-0.236) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.837 (+/-0.332) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.948 (+/-0.057) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.486 (+/-0.032) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.82 (+/-0.34) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.945 (+/-0.083) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.503 (+/-0.042) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.722 (+/-0.399) for {'activation': 'logistic', 'early_stopping': True, 'hidden_layer_sizes': (18,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "mlp = MLPClassifier()\n",
    "scaler = preprocessing.StandardScaler().fit(tr_features)\n",
    "tr_features_scaled=scaler.transform(tr_features)\n",
    "\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(3,), (50,), (18,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'early_stopping' : [True]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(mlp, parameters, cv=5)\n",
    "cv.fit(tr_features_scaled, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(3,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='lbfgs',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OCmodel_MLP.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, 'OCmodel_MLP.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest - Model fitting, Cross validation and hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 4, 'n_estimators': 5}\n",
      "\n",
      "0.938 (+/-0.051) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.938 (+/-0.064) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.934 (+/-0.055) for {'max_depth': 2, 'n_estimators': 250}\n",
      "0.948 (+/-0.049) for {'max_depth': 4, 'n_estimators': 5}\n",
      "0.934 (+/-0.051) for {'max_depth': 4, 'n_estimators': 50}\n",
      "0.941 (+/-0.052) for {'max_depth': 4, 'n_estimators': 250}\n",
      "0.941 (+/-0.036) for {'max_depth': 8, 'n_estimators': 5}\n",
      "0.944 (+/-0.034) for {'max_depth': 8, 'n_estimators': 50}\n",
      "0.948 (+/-0.038) for {'max_depth': 8, 'n_estimators': 250}\n",
      "0.944 (+/-0.055) for {'max_depth': 16, 'n_estimators': 5}\n",
      "0.944 (+/-0.051) for {'max_depth': 16, 'n_estimators': 50}\n",
      "0.944 (+/-0.04) for {'max_depth': 16, 'n_estimators': 250}\n",
      "0.92 (+/-0.035) for {'max_depth': 32, 'n_estimators': 5}\n",
      "0.941 (+/-0.035) for {'max_depth': 32, 'n_estimators': 50}\n",
      "0.948 (+/-0.044) for {'max_depth': 32, 'n_estimators': 250}\n",
      "0.934 (+/-0.04) for {'max_depth': None, 'n_estimators': 5}\n",
      "0.941 (+/-0.052) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.948 (+/-0.038) for {'max_depth': None, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=5,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OCmodel_RandomForest.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, 'OCmodel_RandomForest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boost - Model fitting, Cross validation and hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gb, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cv.best_estimator_, 'OCmodel_GradientBoost.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation (applying saved models on the validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from time import time\n",
    "\n",
    "val_features = pd.read_csv('OCval_features.csv')\n",
    "val_labels = pd.read_csv('OCval_labels.csv')\n",
    "\n",
    "te_features = pd.read_csv('OCtest_features.csv')\n",
    "te_labels = pd.read_csv('OCtest_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(tr_features)\n",
    "val_features_scaled=scaler.transform(val_features)\n",
    "te_features_scaled=scaler.transform(te_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for mdl in ['LR', 'SVM', 'RandomForest', 'GradientBoost']:\n",
    "    models[mdl] = joblib.load('OCmodel_{}.pkl'.format(mdl))\n",
    "    \n",
    "MLPmodel = joblib.load('OCmodel_MLP.pkl'.format(mdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred), 3)\n",
    "    recall = round(recall_score(labels, pred), 3)\n",
    "    print('{} -- Accuracy: {} / Precision: {} / Recall: {} / Latency: {}ms'.format(name,\n",
    "                                                                                   accuracy,\n",
    "                                                                                   precision,\n",
    "                                                                                   recall,\n",
    "                                                                                   round((end - start)*1000, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, val_features, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model('MLP', MLPmodel, val_features_scaled, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Selection (applying saved models on the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model('Random Forest', models['RandomForest'], te_features, te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model('SVM', models['SVM'], te_features, te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model('LR', models['LR'], te_features, te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model('MLP', MLPmodel, te_features_scaled, te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model('GradientBoost ', models['GradientBoost'], te_features, te_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
