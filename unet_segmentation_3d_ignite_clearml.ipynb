{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btho733/Belvin-Personal_Projects/blob/master/unet_segmentation_3d_ignite_clearml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mqoATXZGTAX"
      },
      "source": [
        "Copyright (c) MONAI Consortium  \n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
        "you may not use this file except in compliance with the License.  \n",
        "You may obtain a copy of the License at  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
        "Unless required by applicable law or agreed to in writing, software  \n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
        "See the License for the specific language governing permissions and  \n",
        "limitations under the License.\n",
        "\n",
        "# Experiment Management with ClearML\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/experiment_management/unet_segmentation_3d_ignite_clearml.ipynb)\n",
        "\n",
        "This tutorial shows how to use ClearML to manage MONAI experiments. You can integrate ClearML into your code using MONAI's built-in handlers: `ClearMLImageHandler`, `ClearMLStatsHandler`, and `ModelCheckpoint`.\n",
        "\n",
        "The MONAI example used here is adapted from[3D segmentation with UNet](https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/unet_segmentation_3d_ignite.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "m_5iDugmXcum"
      },
      "source": [
        "## Setup environment\n",
        "\n",
        "`clearml` comes as part of the `monai[all]` installation. For more information about integrating ClearML into your MONAI code, see [here](https://clear.ml/docs/latest/docs/integrations/monai). For more information about using ClearML (experiment management, data management, pipelines, model serving, and more), see [ClearML's official documentation](https://clear.ml/docs/latest/docs/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxKCbdGUXcun",
        "outputId": "cd3efb0b-13ec-460e-f284-6b86b5697ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-03 12:32:47.798433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-03 12:32:47.817954: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-03 12:32:47.823954: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-03 12:32:49.140666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[ignite, nibabel, tensorboard, clearml]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-L36u4sGTAg"
      },
      "source": [
        "## Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VAWF4EftGTAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b43d92-7ed1-469c-e5d9-f471f0f94851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONAI version: 1.5.dev2444\n",
            "Numpy version: 1.26.4\n",
            "Pytorch version: 2.5.0+cu121\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: c70fbd8ff919cabaacfabcbdbf28aa435ae622f9\n",
            "MONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: 0.4.11\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 5.3.2\n",
            "scikit-image version: 0.24.0\n",
            "scipy version: 1.13.1\n",
            "Pillow version: 10.4.0\n",
            "Tensorboard version: 2.17.0\n",
            "gdown version: 5.2.0\n",
            "TorchVision version: 0.20.0+cu121\n",
            "tqdm version: 4.66.6\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 5.9.5\n",
            "pandas version: 2.2.2\n",
            "einops version: 0.8.0\n",
            "transformers version: 4.44.2\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: 1.16.5\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import tempfile\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from monai.config import print_config\n",
        "from monai.data import ArrayDataset, create_test_image_3d, decollate_batch, DataLoader\n",
        "from monai.handlers import (\n",
        "    MeanDice,\n",
        "    StatsHandler,\n",
        ")\n",
        "\n",
        "# import the clearml handlers\n",
        "from monai.handlers.clearml_handlers import ClearMLImageHandler, ClearMLStatsHandler\n",
        "from monai.losses import DiceLoss\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    EnsureChannelFirst,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandSpatialCrop,\n",
        "    Resize,\n",
        "    ScaleIntensity,\n",
        ")\n",
        "from monai.utils import first\n",
        "\n",
        "import ignite\n",
        "import torch\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "L388puuoXcun"
      },
      "source": [
        "## Setup ClearML âš“\n",
        "\n",
        "1. To keep track of your experiments and/or data, ClearML needs to communicate to a server. You have 2 server options:\n",
        "\n",
        "  * Sign up for free to the [ClearML Hosted Service](https://app.clear.ml/)\n",
        "  * Set up your own server, see [here](https://clear.ml/docs/latest/docs/deploying_clearml/clearml_server).\n",
        "\n",
        "2. Add your ClearML credentials below. ClearML will use these credentials to connect to your server (see instructions for generating credentials [here](https://clear.ml/docs/latest/docs/getting_started/ds/ds_first_steps/#jupyter-notebook))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ChKgfQzMXcuo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0b8022-b669-4c81-df82-e139bde0c706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
            "env: CLEARML_API_HOST=https://api.clear.ml\n",
            "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
            "env: CLEARML_API_ACCESS_KEY=0JQ75534YAO6ZGWPJRZYFJQG3URDZI\n",
            "env: CLEARML_API_SECRET_KEY=hCdASFPHWik-nwVxnc8RyijPnrnS4Q7UOnQKyjLGRgUjDXLvSg5jeKoNKf6ioNhuWdY\n"
          ]
        }
      ],
      "source": [
        "# clearml credentials\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=0JQ75534YAO6ZGWPJRZYFJQG3URDZI\n",
        "%env CLEARML_API_SECRET_KEY=hCdASFPHWik-nwVxnc8RyijPnrnS4Q7UOnQKyjLGRgUjDXLvSg5jeKoNKf6ioNhuWdY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBN8rQJcGTAk"
      },
      "source": [
        "## Setup data directory\n",
        "\n",
        "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
        "This allows you to save results and reuse downloads.  \n",
        "If not specified a temporary directory will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "BSjqI-ZBGTAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab2d9d2-2924-424c-bfe9-1d73439e3d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmpvjuivsgo\n"
          ]
        }
      ],
      "source": [
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "if directory is not None:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzxP-l1nGTAl"
      },
      "source": [
        "## Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GGHooZZwGTAl"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIDTWNVxGTAm"
      },
      "source": [
        "## Setup demo data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "l0jR_jz8GTAn"
      },
      "outputs": [],
      "source": [
        "for i in range(40):\n",
        "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1)\n",
        "\n",
        "    n = nib.Nifti1Image(im, np.eye(4))\n",
        "    nib.save(n, os.path.join(root_dir, f\"im{i}.nii.gz\"))\n",
        "\n",
        "    n = nib.Nifti1Image(seg, np.eye(4))\n",
        "    nib.save(n, os.path.join(root_dir, f\"seg{i}.nii.gz\"))\n",
        "\n",
        "images = sorted(glob.glob(os.path.join(root_dir, \"im*.nii.gz\")))\n",
        "segs = sorted(glob.glob(os.path.join(root_dir, \"seg*.nii.gz\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FUIYNO0GTAn"
      },
      "source": [
        "## Setup transforms, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "g5gz3rECGTAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce769e8d-58a5-443c-84f6-d392b8050d7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 1, 96, 96, 96]) torch.Size([10, 1, 96, 96, 96])\n"
          ]
        }
      ],
      "source": [
        "# Define transforms for image and segmentation\n",
        "imtrans = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        ScaleIntensity(),\n",
        "        EnsureChannelFirst(),\n",
        "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
        "    ]\n",
        ")\n",
        "segtrans = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        EnsureChannelFirst(),\n",
        "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define nifti dataset, dataloader\n",
        "ds = ArrayDataset(images, imtrans, segs, segtrans)\n",
        "# loader = DataLoader(ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "loader = DataLoader(ds, batch_size=10, num_workers=2, pin_memory=False)\n",
        "im, seg = first(loader)\n",
        "print(im.shape, seg.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zl4_zeSGTAp"
      },
      "source": [
        "## Create Model, Loss, Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "XT1D-a1-GTAp"
      },
      "outputs": [],
      "source": [
        "# Create UNet, DiceLoss and Adam optimizer\n",
        "\n",
        "device = None  # torch.device(\"cuda:0\")\n",
        "net = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        ").to(device)\n",
        "\n",
        "loss = DiceLoss(sigmoid=True)\n",
        "lr = 1e-3\n",
        "opt = torch.optim.Adam(net.parameters(), lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvduwsk8GTBm"
      },
      "source": [
        "## Create supervised_trainer using ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "9Ocpt_MOGTBn"
      },
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "trainer = ignite.engine.create_supervised_trainer(net, opt, loss, device, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vo9Eq33GTBn"
      },
      "source": [
        "## Set up event handlers for checkpointing and logging\n",
        "\n",
        "Using a ClearML handler creates a ClearML Task, which captures your experiment's models, scalars, images, and more.\n",
        "\n",
        "The console output displays the task ID and a link to the task's page in the ClearML web UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "cZTtFnySGTBo"
      },
      "outputs": [],
      "source": [
        "# optional section for checkpoint and clearml logging\n",
        "# adding checkpoint handler to save models (network\n",
        "# params and optimizer stats) during training\n",
        "log_dir = os.path.join(root_dir, \"logs\")\n",
        "checkpoint_handler = ignite.handlers.ModelCheckpoint(log_dir, \"net\", n_saved=10, require_empty=False)\n",
        "trainer.add_event_handler(\n",
        "    event_name=ignite.engine.Events.EPOCH_COMPLETED,\n",
        "    handler=checkpoint_handler,\n",
        "    to_save={\"net\": net, \"opt\": opt},\n",
        ")\n",
        "\n",
        "# StatsHandler prints loss at every iteration\n",
        "# user can also customize print functions and can use output_transform to convert\n",
        "# engine.state.output if it's not a loss value\n",
        "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
        "train_stats_handler.attach(trainer)\n",
        "\n",
        "\n",
        "# ClearMLStatsHandler plots loss at every iteration\n",
        "# Creates a ClearML Task which logs the scalar plots\n",
        "task_name = \"UNet segmentation 3d-12 epochs\"\n",
        "project_name = \"MONAI example\"\n",
        "\n",
        "train_clearml_stats_handler = ClearMLStatsHandler(\n",
        "    task_name=task_name, project_name=project_name, log_dir=log_dir, output_transform=lambda x: x\n",
        ")\n",
        "train_clearml_stats_handler.attach(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBv81ENGGTBp"
      },
      "source": [
        "## Add Validation every N epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "VYte_Cw6GTBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5775ad25-f00a-4e4c-a214-0f934fe3ed2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x7a579ff5c0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# optional section for model validation during training\n",
        "validation_every_n_epochs = 1\n",
        "# Set parameters for validation\n",
        "metric_name = \"Mean_Dice\"\n",
        "# add evaluation metric to the evaluator engine\n",
        "val_metrics = {metric_name: MeanDice()}\n",
        "post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "post_label = Compose([AsDiscrete(threshold=0.5)])\n",
        "# Ignite evaluator expects batch=(img, seg) and\n",
        "# returns output=(y_pred, y) at every iteration,\n",
        "# user can add output_transform to return other values\n",
        "evaluator = ignite.engine.create_supervised_evaluator(\n",
        "    net,\n",
        "    val_metrics,\n",
        "    device,\n",
        "    True,\n",
        "    output_transform=lambda x, y, y_pred: (\n",
        "        [post_pred(i) for i in decollate_batch(y_pred)],\n",
        "        [post_label(i) for i in decollate_batch(y)],\n",
        "    ),\n",
        ")\n",
        "\n",
        "# create a validation data loader\n",
        "val_imtrans = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        ScaleIntensity(),\n",
        "        EnsureChannelFirst(),\n",
        "        Resize((96, 96, 96)),\n",
        "    ]\n",
        ")\n",
        "val_segtrans = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        EnsureChannelFirst(),\n",
        "        Resize((96, 96, 96)),\n",
        "    ]\n",
        ")\n",
        "val_ds = ArrayDataset(images[21:], val_imtrans, segs[21:], val_segtrans)\n",
        "# val_loader = DataLoader(val_ds, batch_size=5, num_workers=8, pin_memory=torch.cuda.is_available())\n",
        "val_loader = DataLoader(val_ds, batch_size=5, num_workers=2, pin_memory=False)\n",
        "\n",
        "\n",
        "@trainer.on(ignite.engine.Events.EPOCH_COMPLETED(every=validation_every_n_epochs))\n",
        "def run_validation(engine):\n",
        "    evaluator.run(val_loader)\n",
        "\n",
        "\n",
        "# Add stats event handler to print validation stats via evaluator\n",
        "val_stats_handler = StatsHandler(\n",
        "    name=\"evaluator\",\n",
        "    # no need to print loss value, so disable per iteration output\n",
        "    output_transform=lambda x: None,\n",
        "    # fetch global epoch number from trainer\n",
        "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
        ")\n",
        "val_stats_handler.attach(evaluator)\n",
        "\n",
        "# add handler to record metrics to clearml at every validation epoch\n",
        "val_clearml_stats_handler = ClearMLStatsHandler(\n",
        "    log_dir=log_dir,\n",
        "    # no need to plot loss value, so disable per iteration output\n",
        "    output_transform=lambda x: None,\n",
        "    # fetch global epoch number from trainer\n",
        "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
        ")\n",
        "val_clearml_stats_handler.attach(evaluator)\n",
        "\n",
        "# add handler to draw the first image and the corresponding\n",
        "# label and model output in the last batch\n",
        "# here we draw the 3D output as GIF format along Depth\n",
        "# axis, at every validation epoch\n",
        "val_clearml_image_handler = ClearMLImageHandler(\n",
        "    task_name=task_name,\n",
        "    project_name=project_name,\n",
        "    log_dir=log_dir,\n",
        "    batch_transform=lambda batch: (batch[0], batch[1]),\n",
        "    output_transform=lambda output: output[0],\n",
        "    global_iter_transform=lambda x: trainer.state.epoch,\n",
        ")\n",
        "evaluator.add_event_handler(\n",
        "    event_name=ignite.engine.Events.EPOCH_COMPLETED,\n",
        "    handler=val_clearml_image_handler,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxXixOfHGTBq"
      },
      "source": [
        "## Run training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kW0K4mxIGTBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579821c4-bec9-48ce-cdc1-d85e820a8f6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-03 12:33:18,233 - INFO - Epoch: 1/12, Iter: 1/4 -- Loss: 0.6264 \n",
            "2024-11-03 12:33:24,201 - INFO - Epoch: 1/12, Iter: 2/4 -- Loss: 0.6223 \n",
            "2024-11-03 12:33:33,386 - INFO - Epoch: 1/12, Iter: 3/4 -- Loss: 0.5954 \n",
            "2024-11-03 12:33:39,287 - INFO - Epoch: 1/12, Iter: 4/4 -- Loss: 0.6541 \n",
            "2024-11-03 12:33:52,083 - INFO - Epoch[1] Metrics -- Mean_Dice: 0.2440 \n",
            "2024-11-03 12:33:59,847 - INFO - Epoch: 2/12, Iter: 1/4 -- Loss: 0.6080 \n",
            "2024-11-03 12:34:07,478 - INFO - Epoch: 2/12, Iter: 2/4 -- Loss: 0.6194 \n",
            "2024-11-03 12:34:14,787 - INFO - Epoch: 2/12, Iter: 3/4 -- Loss: 0.5780 \n",
            "2024-11-03 12:34:20,548 - INFO - Epoch: 2/12, Iter: 4/4 -- Loss: 0.5901 \n",
            "2024-11-03 12:34:35,075 - INFO - Epoch[2] Metrics -- Mean_Dice: 0.3000 \n",
            "2024-11-03 12:34:42,999 - INFO - Epoch: 3/12, Iter: 1/4 -- Loss: 0.5794 \n",
            "2024-11-03 12:34:51,844 - INFO - Epoch: 3/12, Iter: 2/4 -- Loss: 0.5888 \n",
            "2024-11-03 12:34:58,075 - INFO - Epoch: 3/12, Iter: 3/4 -- Loss: 0.5688 \n",
            "2024-11-03 12:35:06,785 - INFO - Epoch: 3/12, Iter: 4/4 -- Loss: 0.5692 \n",
            "2024-11-03 12:35:16,002 - INFO - Epoch[3] Metrics -- Mean_Dice: 0.3857 \n",
            "2024-11-03 12:35:26,955 - INFO - Epoch: 4/12, Iter: 1/4 -- Loss: 0.5410 \n",
            "2024-11-03 12:35:34,342 - INFO - Epoch: 4/12, Iter: 2/4 -- Loss: 0.5946 \n",
            "2024-11-03 12:35:42,993 - INFO - Epoch: 4/12, Iter: 3/4 -- Loss: 0.5656 \n",
            "2024-11-03 12:35:49,491 - INFO - Epoch: 4/12, Iter: 4/4 -- Loss: 0.5139 \n",
            "2024-11-03 12:35:59,193 - INFO - Epoch[4] Metrics -- Mean_Dice: 0.4984 \n",
            "2024-11-03 12:36:07,866 - INFO - Epoch: 5/12, Iter: 1/4 -- Loss: 0.5297 \n",
            "2024-11-03 12:36:16,072 - INFO - Epoch: 5/12, Iter: 2/4 -- Loss: 0.5110 \n",
            "2024-11-03 12:36:22,827 - INFO - Epoch: 5/12, Iter: 3/4 -- Loss: 0.4966 \n",
            "2024-11-03 12:36:28,667 - INFO - Epoch: 5/12, Iter: 4/4 -- Loss: 0.5979 \n",
            "2024-11-03 12:36:42,496 - INFO - Epoch[5] Metrics -- Mean_Dice: 0.6685 \n",
            "2024-11-03 12:36:50,374 - INFO - Epoch: 6/12, Iter: 1/4 -- Loss: 0.5428 \n",
            "2024-11-03 12:36:59,484 - INFO - Epoch: 6/12, Iter: 2/4 -- Loss: 0.5228 \n",
            "2024-11-03 12:37:05,429 - INFO - Epoch: 6/12, Iter: 3/4 -- Loss: 0.4765 \n",
            "2024-11-03 12:37:14,370 - INFO - Epoch: 6/12, Iter: 4/4 -- Loss: 0.4895 \n",
            "2024-11-03 12:37:24,576 - INFO - Epoch[6] Metrics -- Mean_Dice: 0.7543 \n",
            "2024-11-03 12:37:35,035 - INFO - Epoch: 7/12, Iter: 1/4 -- Loss: 0.4912 \n",
            "2024-11-03 12:37:41,611 - INFO - Epoch: 7/12, Iter: 2/4 -- Loss: 0.4957 \n",
            "2024-11-03 12:37:49,161 - INFO - Epoch: 7/12, Iter: 3/4 -- Loss: 0.5500 \n",
            "2024-11-03 12:37:57,477 - INFO - Epoch: 7/12, Iter: 4/4 -- Loss: 0.4414 \n",
            "2024-11-03 12:38:06,265 - INFO - Epoch[7] Metrics -- Mean_Dice: 0.7860 \n",
            "2024-11-03 12:38:17,261 - INFO - Epoch: 8/12, Iter: 1/4 -- Loss: 0.5150 \n",
            "2024-11-03 12:38:23,740 - INFO - Epoch: 8/12, Iter: 2/4 -- Loss: 0.4617 \n",
            "2024-11-03 12:38:32,762 - INFO - Epoch: 8/12, Iter: 3/4 -- Loss: 0.5192 \n",
            "2024-11-03 12:38:38,590 - INFO - Epoch: 8/12, Iter: 4/4 -- Loss: 0.4283 \n",
            "2024-11-03 12:38:48,827 - INFO - Epoch[8] Metrics -- Mean_Dice: 0.8160 \n",
            "2024-11-03 12:38:57,670 - INFO - Epoch: 9/12, Iter: 1/4 -- Loss: 0.4089 \n",
            "2024-11-03 12:39:06,118 - INFO - Epoch: 9/12, Iter: 2/4 -- Loss: 0.4581 \n",
            "2024-11-03 12:39:12,542 - INFO - Epoch: 9/12, Iter: 3/4 -- Loss: 0.5112 \n",
            "2024-11-03 12:39:18,863 - INFO - Epoch: 9/12, Iter: 4/4 -- Loss: 0.4683 \n",
            "2024-11-03 12:39:32,795 - INFO - Epoch[9] Metrics -- Mean_Dice: 0.8482 \n",
            "2024-11-03 12:39:40,394 - INFO - Epoch: 10/12, Iter: 1/4 -- Loss: 0.4654 \n",
            "2024-11-03 12:39:49,601 - INFO - Epoch: 10/12, Iter: 2/4 -- Loss: 0.4486 \n",
            "2024-11-03 12:39:55,510 - INFO - Epoch: 10/12, Iter: 3/4 -- Loss: 0.4520 \n",
            "2024-11-03 12:40:04,212 - INFO - Epoch: 10/12, Iter: 4/4 -- Loss: 0.4501 \n",
            "2024-11-03 12:40:14,107 - INFO - Epoch[10] Metrics -- Mean_Dice: 0.8630 \n",
            "2024-11-03 12:40:24,889 - INFO - Epoch: 11/12, Iter: 1/4 -- Loss: 0.5229 \n",
            "2024-11-03 12:40:30,806 - INFO - Epoch: 11/12, Iter: 2/4 -- Loss: 0.4007 \n",
            "2024-11-03 12:40:38,044 - INFO - Epoch: 11/12, Iter: 3/4 -- Loss: 0.4168 \n",
            "2024-11-03 12:40:46,007 - INFO - Epoch: 11/12, Iter: 4/4 -- Loss: 0.4365 \n",
            "2024-11-03 12:40:54,310 - INFO - Epoch[11] Metrics -- Mean_Dice: 0.8774 \n",
            "2024-11-03 12:41:05,510 - INFO - Epoch: 12/12, Iter: 1/4 -- Loss: 0.4130 \n",
            "2024-11-03 12:41:11,708 - INFO - Epoch: 12/12, Iter: 2/4 -- Loss: 0.4334 \n",
            "2024-11-03 12:41:20,223 - INFO - Epoch: 12/12, Iter: 3/4 -- Loss: 0.4641 \n",
            "2024-11-03 12:41:26,270 - INFO - Epoch: 12/12, Iter: 4/4 -- Loss: 0.4597 \n",
            "2024-11-03 12:41:36,776 - INFO - Epoch[12] Metrics -- Mean_Dice: 0.8786 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 48\n",
              "\tepoch: 12\n",
              "\tepoch_length: 4\n",
              "\tmax_epochs: 12\n",
              "\toutput: 0.45969900488853455\n",
              "\tbatch: <class 'list'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'monai.data.dataloader.DataLoader'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# create a training data loader\n",
        "train_ds = ArrayDataset(images[:20], imtrans, segs[:20], segtrans)\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=5,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    # pin_memory=torch.cuda.is_available(),\n",
        "    pin_memory=False,\n",
        ")\n",
        "\n",
        "max_epochs = 12\n",
        "trainer.run(train_loader, max_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bPDjtbE7sCP"
      },
      "source": [
        "## Visualize results\n",
        "\n",
        "ClearML captures the models, scalar plots, and images logged with `ModelCheckpoint`, `ClearMLImageHandler`, and `ClearMLStatsHandler` respectively. View them in ClearML's web UI. When a task is created, the console output displays the task ID and a link to the task's page in the ClearML web UI.\n",
        "\n",
        "### Models\n",
        "All model checkpoints logged with ModelCheckpoint can be viewed in the task's **Artifacts** tab.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uya6hN7At-C6"
      },
      "source": [
        "![MONAI ClearML Models](https://github.com/Project-MONAI/tutorials/blob/main/figures/monai_clearml_models.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLs1tEXRt-Pp"
      },
      "source": [
        "### Scalars\n",
        "\n",
        "View the logged metric plots in the task's **Scalars** tab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCLhp4e2uKsd"
      },
      "source": [
        "![MONAI ClearML scalars.png](https://github.com/Project-MONAI/tutorials/blob/main/figures/monai_clearml_scalars.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjfeorgJuLUN"
      },
      "source": [
        "### Debug Samples\n",
        "\n",
        "View all images logged through ClearMLImageHandler in the task's **Debug Samples** tab. You can view the samples by metric at any iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFLJauKxt-Yy"
      },
      "source": [
        "![MONAI ClearML Debug Samples.png](https://github.com/Project-MONAI/tutorials/blob/main/figures/monai_clearml_debug_samples.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFlaQUTXGTBv"
      },
      "source": [
        "## Cleanup data directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "w6JE9lVQGTBw"
      },
      "outputs": [],
      "source": [
        "if directory is None:\n",
        "    shutil.rmtree(root_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT-5Zxg_7Ajm"
      },
      "source": [
        "\n",
        "## Close the ClearML Task\n",
        "This changes the task status to `Completed`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "BAD6ACGGOLU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc2b9e6-1715-4caa-98cf-1560fa0cec18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-03 12:41:57,917 - clearml.log - INFO - Flush timeout 10.0s exceeded, dropping last 0 lines\n"
          ]
        }
      ],
      "source": [
        "val_clearml_image_handler.clearml_task.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}